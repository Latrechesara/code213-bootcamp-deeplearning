{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780b3f1f",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left;\">\n",
    "  <a href=\"https://code213.tech/\" target=\"_blank\">\n",
    "    <img src=\"code213.PNG\" alt=\"Code213 Logo\" width=\"200\"/>\n",
    "  </a>\n",
    "  <p><em>Prepared by Latreche Sara</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc3279",
   "metadata": {},
   "source": [
    "# 5.0 — Data Handling (`tf.data.Dataset`)\n",
    "<img src=\"https://www.tensorflow.org/images/tf_logo_social.png\" alt=\"TensorFlow Logo\" width=\"200\"/>\n",
    "\n",
    "**Why use `tf.data.Dataset`?**  \n",
    "\n",
    "- Efficiently **load and preprocess data** for training and evaluation  \n",
    "- Handle **large datasets** that do not fit into memory  \n",
    "- Provide **pipelines with batching, shuffling, mapping, and prefetching**  \n",
    "- Fully compatible with TensorFlow models (`model.fit`) and custom training loops\n",
    "## Table of Contents  \n",
    "\n",
    "- [1 - Packages](#1)  \n",
    "- [2 - Outline of the Notebook](#2)  \n",
    "- [3 - Creating a Dataset](#3)  \n",
    "  - [3.1 - From Python lists/arrays](#3-1)  \n",
    "  - [3.2 - From TensorFlow tensors](#3-2)  \n",
    "- [4 - Transforming Datasets](#4)  \n",
    "  - [4.1 - Mapping functions](#4-1)  \n",
    "  - [4.2 - Shuffling and batching](#4-2)  \n",
    "  - [4.3 - Prefetching](#4-3)  \n",
    "- [5 - Iterating Over a Dataset](#5)  \n",
    "- [6 - Using Dataset with Model](#6)  \n",
    "- [7 - Exercises](#7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5147355",
   "metadata": {},
   "source": [
    "## 1 - Packages <a name=\"1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdb05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab7e9e",
   "metadata": {},
   "source": [
    "## 2 - Outline of the Notebook <a name=\"2\"></a>\n",
    "\n",
    "This notebook covers:  \n",
    "\n",
    "1. Creating datasets from Python lists or tensors  \n",
    "2. Transforming datasets using `map`, `batch`, `shuffle`, `prefetch`  \n",
    "3. Iterating through a dataset  \n",
    "4. Using datasets directly with a TensorFlow model  \n",
    "5. Exercises for practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "317e51fe",
   "metadata": {},
   "source": [
    "## 3 - Creating a Dataset <a name=\"3\"></a>\n",
    "### 3.1 - From Python lists/arrays <a name=\"3-1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed261efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=3>, <tf.Tensor: shape=(), dtype=int64, numpy=6>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=4>, <tf.Tensor: shape=(), dtype=int64, numpy=8>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=5>, <tf.Tensor: shape=(), dtype=int64, numpy=10>)\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "# Print elements\n",
    "for element in dataset:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edf95d",
   "metadata": {},
   "source": [
    "### 3.2 - From TensorFlow tensors <a name=\"3-2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1166ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=10>, <tf.Tensor: shape=(), dtype=int32, numpy=100>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=20>, <tf.Tensor: shape=(), dtype=int32, numpy=200>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=30>, <tf.Tensor: shape=(), dtype=int32, numpy=300>)\n"
     ]
    }
   ],
   "source": [
    "x_tf = tf.constant([10, 20, 30])\n",
    "y_tf = tf.constant([100, 200, 300])\n",
    "\n",
    "dataset_tf = tf.data.Dataset.from_tensor_slices((x_tf, y_tf))\n",
    "for elem in dataset_tf:\n",
    "    print(elem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f06964",
   "metadata": {},
   "source": [
    "## 4 - Transforming Datasets <a name=\"4\"></a>\n",
    "### 4.1 - Mapping functions <a name=\"4-1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86963242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=4>, <tf.Tensor: shape=(), dtype=int64, numpy=16>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=9>, <tf.Tensor: shape=(), dtype=int64, numpy=36>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=16>, <tf.Tensor: shape=(), dtype=int64, numpy=64>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=25>, <tf.Tensor: shape=(), dtype=int64, numpy=100>)\n"
     ]
    }
   ],
   "source": [
    "# Apply a function to each element\n",
    "def square(x, y):\n",
    "    return x**2, y**2\n",
    "\n",
    "dataset_mapped = dataset.map(square)\n",
    "for elem in dataset_mapped:\n",
    "    print(elem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c942d4",
   "metadata": {},
   "source": [
    "### 4.2 - Shuffling and batching <a name=\"4-2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9207ef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 4])>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([4, 8])>)\n",
      "(<tf.Tensor: shape=(2,), dtype=int64, numpy=array([5, 3])>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([10,  6])>)\n",
      "(<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([2])>)\n"
     ]
    }
   ],
   "source": [
    "dataset_shuffled = dataset.shuffle(buffer_size=5).batch(2)\n",
    "for batch in dataset_shuffled:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b765d4",
   "metadata": {},
   "source": [
    "### 4.3 - Prefetching <a name=\"4-3\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62647335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 2])>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 4])>)\n",
      "(<tf.Tensor: shape=(2,), dtype=int64, numpy=array([3, 4])>, <tf.Tensor: shape=(2,), dtype=int64, numpy=array([6, 8])>)\n",
      "(<tf.Tensor: shape=(1,), dtype=int64, numpy=array([5])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([10])>)\n"
     ]
    }
   ],
   "source": [
    "dataset_prefetch = dataset.batch(2).prefetch(tf.data.AUTOTUNE)\n",
    "for batch in dataset_prefetch:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9b25a",
   "metadata": {},
   "source": [
    "## 5 - Iterating Over a Dataset <a name=\"5\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a7f510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1 2] y: [2 4]\n",
      "x: [3 4] y: [6 8]\n",
      "x: [5] y: [10]\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in dataset_prefetch:\n",
    "    print(\"x:\", x_batch.numpy(), \"y:\", y_batch.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c58b0",
   "metadata": {},
   "source": [
    "## 6 - Using Dataset with Model <a name=\"6\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895605a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e535df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MatenTech\\AppData\\Local\\anaconda3\\envs\\bd\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.0645 \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7399\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0784\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0145  \n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0099 \n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0101 \n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 \n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0101 \n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0099 \n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x277ff07f770>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build simple model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "# Train using dataset\n",
    "model.fit(dataset.batch(2), epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff15d7",
   "metadata": {},
   "source": [
    "## 7 - Exercises <a name=\"7\"></a>\n",
    "\n",
    "1. Create a dataset from x = [1,2,3,4,5,6] and y = [10,20,30,40,50,60].  \n",
    "2. Shuffle the dataset and batch it with batch size 3.  \n",
    "3. Map a function to multiply both x and y by 2.  \n",
    "4. Use the dataset to train a model for 20 epochs to learn y = 2x.  \n",
    "5. Experiment with `prefetch` and observe training performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231963f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
