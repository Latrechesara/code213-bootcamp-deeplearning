{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d71d11",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left;\">\n",
    "  <a href=\"https://code213.tech/\" target=\"_blank\">\n",
    "    <img src=\"code213.PNG\" alt=\"code213\">\n",
    "  </a>\n",
    "  <p><em>prepared by Latreche Sara</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f82c0",
   "metadata": {},
   "source": [
    "# 10.7 - Model Implementations in PyTorch\n",
    "\n",
    "PyTorch provides flexible ways to **define and implement models** for deep learning.  \n",
    "\n",
    "### Key Points\n",
    "1. **Sequential Models**\n",
    "   - Use `nn.Sequential` to stack layers in order  \n",
    "   - Easy for simple feedforward architectures\n",
    "\n",
    "2. **Custom Models**\n",
    "   - Subclass `nn.Module`  \n",
    "   - Define `__init__()` for layers and `forward()` for forward pass  \n",
    "   - Allows complete flexibility for any architecture\n",
    "\n",
    "3. **Predefined Models**\n",
    "   - PyTorch provides models in `torchvision.models`  \n",
    "   - Useful for transfer learning\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, we will cover:  \n",
    "- Implementing a simple feedforward network  \n",
    "- Defining custom models with `nn.Module`  \n",
    "- Using models with GPU and DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cabb14",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Sequential Model](#1)\n",
    "- [2 - Custom Model with nn.Module](#2)\n",
    "- [3 - Using Predefined Models](#3)\n",
    "- [4 - Training a Model](#4)\n",
    "- [5 - Practice Exercises](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d5baa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec0bf71",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Sequential Model\n",
    "\n",
    "`nn.Sequential` allows you to **stack layers sequentially** to define simple feedforward networks.\n",
    "\n",
    "### Key Points\n",
    "- Layers are executed in the order they are added  \n",
    "- Easy to implement simple networks without defining a `forward()` method  \n",
    "- Supports any layer type: `Linear`, `ReLU`, `Dropout`, etc.\n",
    "\n",
    "Example architecture:\n",
    "- Input: 4 features  \n",
    "- Hidden layer: 5 neurons, ReLU activation  \n",
    "- Output: 3 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec450c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2562e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple sequential model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 3)\n",
    ")\n",
    "\n",
    "# Sample input\n",
    "x = torch.randn(2, 4)\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "print(\"Sequential model output:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ba878",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Custom Model with nn.Module\n",
    "\n",
    "For more complex architectures, we can **subclass `nn.Module`**.  \n",
    "\n",
    "### Key Points\n",
    "- Define layers in `__init__()`  \n",
    "- Define forward computation in `forward()`  \n",
    "- Provides full flexibility for branching, multiple inputs, skip connections, etc.\n",
    "\n",
    "Example architecture:\n",
    "- Input: 4 features  \n",
    "- Hidden layer 1: 6 neurons, ReLU  \n",
    "- Hidden layer 2: 3 neurons, ReLU  \n",
    "- Output: 2 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64cfff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model output:\n",
      " tensor([[1.0381, 0.3685],\n",
      "        [0.8170, 0.1110]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define custom model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 6)\n",
    "        self.fc2 = nn.Linear(6, 3)\n",
    "        self.fc3 = nn.Linear(3, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create model instance\n",
    "model = CustomModel()\n",
    "\n",
    "# Sample input\n",
    "x = torch.randn(2, 4)\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "print(\"Custom model output:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbc161",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Using Predefined Models\n",
    "\n",
    "PyTorch provides **pretrained models** in `torchvision.models` for tasks like image classification, segmentation, and more.  \n",
    "\n",
    "### Key Points\n",
    "- Pretrained models can be used for **transfer learning**  \n",
    "- Common models: `resnet18`, `vgg16`, `alexnet`  \n",
    "- You can modify the **final layers** for your own number of classes  \n",
    "\n",
    "Example workflow:\n",
    "1. Load a pretrained model  \n",
    "2. Replace the final layer(s) if needed  \n",
    "3. Move model to GPU if available  \n",
    "4. Use DataLoader to feed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00d6fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MatenTech\\AppData\\Local\\anaconda3\\envs\\bd\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MatenTech\\AppData\\Local\\anaconda3\\envs\\bd\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\MatenTech/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained ResNet18 output shape: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pretrained ResNet18\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final layer for 10 classes\n",
    "resnet18.fc = torch.nn.Linear(resnet18.fc.in_features, 10)\n",
    "\n",
    "# Move model to device\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "# Sample input: batch size 2, 3 channels, 224x224 images\n",
    "x = torch.randn(2, 3, 224, 224).to(device)\n",
    "\n",
    "# Forward pass\n",
    "output = resnet18(x)\n",
    "print(\"Pretrained ResNet18 output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6691f7",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Training a Model\n",
    "\n",
    "Once a model is defined, we can train it using PyTorch's **training loop**.  \n",
    "\n",
    "### Key Points\n",
    "- Move both **model and data** to the same device (CPU or GPU)  \n",
    "- Define **loss function** and **optimizer**  \n",
    "- Typical training loop:\n",
    "  1. Forward pass: compute predictions  \n",
    "  2. Compute loss  \n",
    "  3. Backward pass: compute gradients  \n",
    "  4. Optimizer step: update weights  \n",
    "  5. Repeat for multiple epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df4f1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6435\n",
      "Epoch 2, Loss: 0.6590\n",
      "Epoch 3, Loss: 0.6754\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Sample dataset\n",
    "x = torch.randn(20, 4)\n",
    "y = torch.randint(0, 2, (20,))\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# Simple model\n",
    "model = nn.Linear(4, 2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5312ee",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Practice Exercises\n",
    "\n",
    "Try the following exercises to reinforce your understanding of **PyTorch model implementations**:\n",
    "\n",
    "---\n",
    "\n",
    "### **Exercise 1: Sequential Model**\n",
    "- Create a `nn.Sequential` model with:\n",
    "  - Input: 3 features\n",
    "  - Hidden layer: 4 neurons, ReLU activation\n",
    "  - Output: 2 neurons\n",
    "- Forward a random input tensor and print the output\n",
    "\n",
    "---\n",
    "\n",
    "### **Exercise 2: Custom Model**\n",
    "- Subclass `nn.Module` to create a model with:\n",
    "  - Input: 3 features\n",
    "  - Hidden layer 1: 5 neurons, ReLU\n",
    "  - Hidden layer 2: 3 neurons, ReLU\n",
    "  - Output: 2 neurons\n",
    "- Forward a random input tensor and print the output\n",
    "\n",
    "---\n",
    "\n",
    "### **Exercise 3: Pretrained Model**\n",
    "- Load a pretrained `resnet18`  \n",
    "- Modify the final layer to have 5 output classes  \n",
    "- Forward a random tensor of shape `(2, 3, 224, 224)` and print the output shape\n",
    "\n",
    "---\n",
    "\n",
    "### **Exercise 4: Training Loop**\n",
    "- Create a small dataset with 12 samples, 3 features each, and labels 0 or 1  \n",
    "- Define a simple linear model  \n",
    "- Train it for 2 epochs using `CrossEntropyLoss` and SGD optimizer  \n",
    "- Print the loss after each batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c3ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential model output: tensor([[0.4797, 0.6344]], grad_fn=<AddmmBackward0>)\n",
      "Custom model output: tensor([[0.4419, 0.2808]], grad_fn=<AddmmBackward0>)\n",
      "Pretrained ResNet18 output shape: torch.Size([2, 5])\n",
      "Epoch 1, Loss: 1.2573\n",
      "Epoch 1, Loss: 0.7442\n",
      "Epoch 1, Loss: 0.8245\n",
      "Epoch 2, Loss: 1.6021\n",
      "Epoch 2, Loss: 0.7905\n",
      "Epoch 2, Loss: 0.3885\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 1: Sequential Model\n",
    "# ----------------------------\n",
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(3, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 2)\n",
    ").to(device)\n",
    "\n",
    "x = torch.randn(1, 3).to(device)\n",
    "print(\"Sequential model output:\", seq_model(x))\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 2: Custom Model\n",
    "# ----------------------------\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "        self.fc3 = nn.Linear(3, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "custom_model = CustomModel().to(device)\n",
    "x = torch.randn(1, 3).to(device)\n",
    "print(\"Custom model output:\", custom_model(x))\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 3: Pretrained Model\n",
    "# ----------------------------\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 5)\n",
    "resnet18 = resnet18.to(device)\n",
    "x_img = torch.randn(2, 3, 224, 224).to(device)\n",
    "print(\"Pretrained ResNet18 output shape:\", resnet18(x_img).shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 4: Training Loop\n",
    "# ----------------------------\n",
    "data = torch.randn(12, 3)\n",
    "labels = torch.randint(0, 2, (12,))\n",
    "dataset = TensorDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "model = nn.Linear(3, 2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d7386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
