{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0813eb",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left;\">\n",
    "  <a href=\"https://code213.tech/\" target=\"_blank\">\n",
    "    <img src=\"../code213.PNG\" alt=\"code213\">\n",
    "  </a>\n",
    "  <p><em>prepared by Latreche Sara</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ac226",
   "metadata": {},
   "source": [
    "# 1.0 — Getting Started with PyTorch\n",
    "<img src=\"https://pytorch.org/assets/images/pytorch-logo.png\" alt=\"PyTorch Logo\" width=\"200\"/>\n",
    "\n",
    "**What is PyTorch?**  \n",
    "\n",
    "PyTorch is an **open-source deep learning framework** developed by Facebook’s AI Research (FAIR) lab.  \n",
    "It is widely adopted in both **academia** and **industry** because:  \n",
    "\n",
    "-  **Dynamic graphs**: easy to debug and experiment with.  \n",
    "-  **GPU acceleration**: strong CUDA support for fast training.  \n",
    "-  **Rich ecosystem**: libraries like TorchVision, TorchText, and TorchAudio.  \n",
    "-  **Large community**: tutorials, pretrained models, and active contributions.  \n",
    "\n",
    " You can think of PyTorch as both:  \n",
    "- A **scientific computing library** (similar to NumPy but with GPU support).  \n",
    "- A **deep learning framework** (like TensorFlow, but often considered more intuitive).  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents  \n",
    "\n",
    "- [1 - Packages](#1)  \n",
    "- [2 - Outline of the Notebook](#2)  \n",
    "- [3 - Installing and Importing PyTorch](#3)  \n",
    "- [4 - Checking Device (CPU/GPU)](#4)  \n",
    "- [5 - Creating Tensors](#5)  \n",
    "  - [5.1 - From Python lists](#5-1)  \n",
    "  - [5.2 - With built-in functions](#5-2)  \n",
    "- [6 - Tensor Operations](#6)  \n",
    "  - [6.1 - Element-wise operations](#6-1)  \n",
    "  - [6.2 - Dot products](#6-2)  \n",
    "- [7 - Moving Tensors to GPU](#7)  \n",
    "- [8 - Exercises](#8)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297b32a",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186132dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cpu\n",
      "TorchVision version: 0.23.0+cpu\n",
      "TorchAudio version: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "# Numerical operations\n",
    "import numpy as np  \n",
    "\n",
    "# PyTorch ecosystem libraries\n",
    "import torchvision\n",
    "import torchaudio\n",
    "\n",
    "# For plotting (optional, but useful for visualization)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"TorchVision version:\", torchvision.__version__)\n",
    "print(\"TorchAudio version:\", torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c651fec",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Outline of the Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a47ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd06764",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Installing and Importing PyTorch\n",
    "PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab.  \n",
    "It provides a flexible platform for building and training neural networks.  \n",
    "\n",
    "### Installation  \n",
    "\n",
    "To install PyTorch using `pip`, open your terminal and run:  \n",
    "\n",
    "```bash\n",
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407acaab",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Exercises  \n",
    "\n",
    "1. Modify the decay schedule: make $\\epsilon$ decrease **slower** or **faster**.  \n",
    "2. Try a **larger grid size** for the snake. What changes?  \n",
    "3. Fix $\\epsilon=1.0$ (always random). What happens to the score trend?  \n",
    "4. Fix $\\epsilon=0.0$ (always exploit). Why does the agent fail?  \n",
    "5. Add a new reward: -1 per move. Does the agent play differently?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe23bf",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Checking Device (CPU/GPU)  \n",
    "\n",
    "PyTorch can run computations on both **CPU** and **GPU (CUDA-enabled)** devices.  \n",
    "By default, tensors are created on the CPU, but if you have a GPU available, you can accelerate training significantly.  \n",
    "\n",
    "We can check which device is available using the following commands:\n",
    "## 4 - Checking Device (CPU/GPU)  \n",
    "\n",
    "Before we check for device availability in PyTorch, let’s briefly review the types of processors used in deep learning:  \n",
    "![CPU vs GPU vs TPU](../859760b6-1dbd-4a9c-a478-91739ba5ef6b.png)\n",
    "- **CPU (Central Processing Unit):**  \n",
    "  - The \"brain\" of the computer.  \n",
    "  - Optimized for **sequential tasks** and general-purpose computing.  \n",
    "  - Great for running operating systems, applications, and handling logic-intensive tasks.  \n",
    "\n",
    "- **GPU (Graphics Processing Unit):**  \n",
    "  - Originally designed for rendering graphics in games.  \n",
    "  - Contains thousands of smaller cores designed for **parallel processing**.  \n",
    "  - Ideal for deep learning because matrix multiplications and tensor operations can be parallelized.  \n",
    "  - This massively speeds up training compared to CPUs.  \n",
    "\n",
    "- **TPU (Tensor Processing Unit):**  \n",
    "  - Developed by **Google**.  \n",
    "  - Specialized hardware optimized specifically for deep learning and tensor computations.  \n",
    "  - Available on **Google Cloud Platform**.  \n",
    "\n",
    "### Why does a GPU accelerate training?  \n",
    "Deep learning requires performing millions (or even billions) of matrix multiplications and tensor operations.  \n",
    "- On a **CPU**, these operations are executed mostly **sequentially**.  \n",
    "- On a **GPU**, thousands of cores perform these operations **in parallel**, making training much faster.  \n",
    "- **TPUs** take this further by being custom-built for tensor math, which is the core of deep learning.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21cf973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available. Using:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5449e7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "562076b5",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Creating Tensors  \n",
    "<a name='5'></a>\n",
    "## 5 – Creating Tensors  \n",
    "\n",
    "A **tensor** is the fundamental **data structure of PyTorch**.  \n",
    "It is an N-dimensional array used to store data, perform computations, and hold model parameters.  \n",
    "\n",
    "- **0-D Tensor (Scalar):** A single number (e.g., `7`).  \n",
    "- **1-D Tensor (Vector):** A list of numbers (e.g., `[1, 2, 3]`).  \n",
    "- **2-D Tensor (Matrix):** A table/grid of numbers (e.g., `[[1, 2], [3, 4]]`).  \n",
    "- **N-D Tensor:** Higher-order structures (e.g., batches of images, videos, multi-channel signals).  \n",
    "\n",
    "### Visual: Scalars → Vectors → Matrices → Higher-Dimensional Tensors  \n",
    "\n",
    "![Tensors diagram](../tensor.png)\n",
    "\n",
    "### Why Tensors in PyTorch?\n",
    "- Similar to **NumPy arrays**, but optimized for GPU usage.  \n",
    "- Enable **automatic differentiation**, which is crucial for training deep learning models.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9feb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22c635dc",
   "metadata": {},
   "source": [
    "<a name='5-1'></a>\n",
    "### 5.1 - From Python lists  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc0fa6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 5.1 - From Python lists\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(\"Tensor from list:\\n\", x_data)\n",
    "\n",
    "# From NumPy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(\"Tensor from NumPy array:\\n\", x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67a81e",
   "metadata": {},
   "source": [
    "<a name='5-2'></a>\n",
    "### 5.2 - With built-in functions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b3c4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344d4353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      " tensor([[0.3051, 0.2705, 0.8734],\n",
      "        [0.6569, 0.4967, 0.7114]])\n",
      "Ones Tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Zeros Tensor:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# ### 5.2 - With built-in functions\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)   # random values\n",
    "ones_tensor = torch.ones(shape)   # all ones\n",
    "zeros_tensor = torch.zeros(shape) # all zeros\n",
    "\n",
    "print(\"Random Tensor:\\n\", rand_tensor)\n",
    "print(\"Ones Tensor:\\n\", ones_tensor)\n",
    "print(\"Zeros Tensor:\\n\", zeros_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804bc03",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Tensor Operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540fede",
   "metadata": {},
   "source": [
    "<a name='6-1'></a>\n",
    "### 6.1 - Element-wise operations  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6978eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tensor:\n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "Element-wise multiplication:\n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "After in-place addition (+5):\n",
      " tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# ## 6 - Tensor Operations\n",
    "\n",
    "# ### 6.1 - Element-wise operations\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(\"Example tensor:\\n\", tensor)\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(\"Element-wise multiplication:\\n\", tensor * tensor)\n",
    "\n",
    "# In-place addition\n",
    "tensor.add_(5)\n",
    "print(\"After in-place addition (+5):\\n\", tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25decbee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "071a83d1",
   "metadata": {},
   "source": [
    "<a name='6-2'></a>\n",
    "### 6.2 - Dot products  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9aaab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication (matmul):\n",
      " tensor([[133., 133., 133., 133.],\n",
      "        [133., 133., 133., 133.],\n",
      "        [133., 133., 133., 133.],\n",
      "        [133., 133., 133., 133.]])\n",
      "Matrix multiplication (@):\n",
      " tensor([[133., 133., 133., 133.],\n",
      "        [133., 133., 133., 133.],\n",
      "        [133., 133., 133., 133.],\n",
      "        [133., 133., 133., 133.]])\n"
     ]
    }
   ],
   "source": [
    "# ### 6.2 - Dot products\n",
    "# Matrix multiplication\n",
    "result1 = tensor.matmul(tensor.T)\n",
    "result2 = tensor @ tensor.T   # shorthand\n",
    "print(\"Matrix multiplication (matmul):\\n\", result1)\n",
    "print(\"Matrix multiplication (@):\\n\", result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fbef87",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Moving Tensors to GPU  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce3479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, running on CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = tensor.to(\"cuda\")\n",
    "    print(\"Tensor moved to GPU:\", gpu_tensor.device)\n",
    "else:\n",
    "    print(\"No GPU found, running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd2e8d",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## 8 - Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4ccb7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
