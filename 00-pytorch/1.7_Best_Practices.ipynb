{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5625ceb6",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left;\">\n",
    "  <a href=\"https://code213.tech/\" target=\"_blank\">\n",
    "    <img src=\"code213.PNG\" alt=\"code213\">\n",
    "  </a>\n",
    "  <p><em>prepared by Latreche Sara</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e19f0",
   "metadata": {},
   "source": [
    "# 10.8 - Best Practices in PyTorch\n",
    "\n",
    "This notebook covers **best practices** for building, training, and deploying PyTorch models.  \n",
    "\n",
    "### Key Points\n",
    "1. **Device management**\n",
    "   - Always check if GPU is available  \n",
    "   - Move tensors and models to the same device\n",
    "\n",
    "2. **Reproducibility**\n",
    "   - Set random seeds for `torch`, `numpy`, and Python `random`  \n",
    "   - Use `torch.backends.cudnn.deterministic=True` for deterministic GPU results\n",
    "\n",
    "3. **Data Handling**\n",
    "   - Use `Dataset` and `DataLoader` for efficient batching  \n",
    "   - Normalize and transform data properly\n",
    "\n",
    "4. **Model Saving and Loading**\n",
    "   - Save only model weights (`state_dict`) for flexibility  \n",
    "   - Use `torch.save()` and `torch.load()`  \n",
    "\n",
    "5. **Training Loop**\n",
    "   - Zero gradients each step: `optimizer.zero_grad()`  \n",
    "   - Track loss and metrics  \n",
    "   - Use `with torch.no_grad()` for validation\n",
    "\n",
    "6. **Mixed Precision & Gradient Clipping**\n",
    "   - For large models, consider `torch.cuda.amp` for faster training  \n",
    "   - Clip gradients to prevent exploding gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f34525",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Device Management](#1)\n",
    "- [2 - Reproducibility](#2)\n",
    "- [3 - Data Handling](#3)\n",
    "- [4 - Model Saving & Loading](#4)\n",
    "- [5 - Training Loop Best Practices](#5)\n",
    "- [6 - Mixed Precision & Gradient Clipping](#6)\n",
    "- [7 - Practice Exercises](#7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63003569",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "019d9c33",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Device Management\n",
    "\n",
    "Proper device management ensures that your **model and data are on the same device**.  \n",
    "\n",
    "### Key Points\n",
    "- Use `torch.cuda.is_available()` to check for GPU  \n",
    "- Use `torch.device('cuda')` for GPU or `torch.device('cpu')` for CPU  \n",
    "- Move tensors and models to the chosen device using `.to(device)`  \n",
    "\n",
    "Benefits:\n",
    "- Avoid runtime errors due to mismatched devices  \n",
    "- Take advantage of GPU acceleration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64c00e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ef012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Sample tensor\n",
    "x = torch.randn(2, 3).to(device)\n",
    "print(\"Tensor device:\", x.device)\n",
    "\n",
    "# Sample model\n",
    "model = nn.Linear(3, 2).to(device)\n",
    "print(\"Model device:\", next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39398a1",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Reproducibility\n",
    "\n",
    "Setting seeds ensures that your experiments are **deterministic and reproducible**.  \n",
    "\n",
    "### Key Points\n",
    "- Set seeds for:\n",
    "  - PyTorch: `torch.manual_seed()`  \n",
    "  - CUDA: `torch.cuda.manual_seed_all()`  \n",
    "  - NumPy: `np.random.seed()`  \n",
    "  - Python: `random.seed()`  \n",
    "- For GPU determinism:\n",
    "  - `torch.backends.cudnn.deterministic = True`  \n",
    "  - `torch.backends.cudnn.benchmark = False`  \n",
    "\n",
    "Benefits:\n",
    "- Helps debug and compare models  \n",
    "- Produces consistent results across runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba33dd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08931195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor x1:\n",
      " tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380,  0.4617]])\n",
      "Random tensor x2:\n",
      " tensor([[ 0.2674,  0.5349,  0.8094],\n",
      "        [ 1.1103, -1.6898, -0.9890],\n",
      "        [ 0.9580,  1.3221,  0.8172]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set seeds\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Test reproducibility\n",
    "x1 = torch.randn(3, 3)\n",
    "x2 = torch.randn(3, 3)\n",
    "print(\"Random tensor x1:\\n\", x1)\n",
    "print(\"Random tensor x2:\\n\", x2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced54fd",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Data Handling\n",
    "\n",
    "Efficient data handling is crucial for training deep learning models.  \n",
    "\n",
    "### Key Points\n",
    "- Use **Dataset** and **DataLoader** for:\n",
    "  - Efficient batching  \n",
    "  - Shuffling data  \n",
    "  - Parallel data loading (`num_workers`)  \n",
    "- Apply **transformations** to preprocess data:\n",
    "  - Normalization  \n",
    "  - Augmentation (flip, rotation, crop)  \n",
    "- Always move batches to the same device as the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d199abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x shape: torch.Size([4, 3, 32, 32])\n",
      "Batch y: tensor([0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Sample dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.randn(10, 3, 32, 32)  # e.g., 32x32 images\n",
    "        self.labels = torch.randint(0, 2, (10,))\n",
    "        self.transform = transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "# Iterate through a batch\n",
    "for x_batch, y_batch in dataloader:\n",
    "    print(\"Batch x shape:\", x_batch.shape)\n",
    "    print(\"Batch y:\", y_batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead051f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4423dfa2",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Model Saving & Loading\n",
    "\n",
    "Saving and loading models properly ensures **flexibility and reproducibility**.  \n",
    "\n",
    "### Key Points\n",
    "- Save only the **model weights** (`state_dict`) for flexibility  \n",
    "- Save the **entire model** if you want to load it directly (less flexible)  \n",
    "- Use `torch.save()` to save and `torch.load()` to load models  \n",
    "\n",
    "Example:\n",
    "- `torch.save(model.state_dict(), \"model.pth\")`  \n",
    "- `model.load_state_dict(torch.load(\"model.pth\"))`  \n",
    "- `model.eval()` sets the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58104025",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239cf95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved.\n",
      "Model loaded and set to eval mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Sample model\n",
    "model = nn.Linear(3, 2)\n",
    "\n",
    "# Save model state_dict\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "print(\"Model weights saved.\")\n",
    "\n",
    "# Load model state_dict\n",
    "model_loaded = nn.Linear(3, 2)\n",
    "model_loaded.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "model_loaded.eval()\n",
    "print(\"Model loaded and set to eval mode.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa023eed",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Training Loop Best Practices\n",
    "\n",
    "Proper training loop management ensures **stable and efficient training**.  \n",
    "\n",
    "### Key Points\n",
    "- **Zero gradients** before each backward pass: `optimizer.zero_grad()`  \n",
    "- **Track loss and metrics** for monitoring  \n",
    "- Use `with torch.no_grad()` for validation to save memory  \n",
    "- Move **both model and data** to the same device  \n",
    "- Save checkpoints periodically to resume training if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257489bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7349\n",
      "Epoch 2, Loss: 0.4746\n",
      "Validation output:\n",
      " tensor([[-0.5966,  0.6238],\n",
      "        [-0.8944,  0.8310],\n",
      "        [-0.6978,  0.6653],\n",
      "        [-0.0489,  0.1887],\n",
      "        [-0.3532,  0.8180]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Sample dataset\n",
    "x = torch.randn(20, 3)\n",
    "y = torch.randint(0, 2, (20,))\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# Sample model\n",
    "model = nn.Linear(3, 2).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop with best practices\n",
    "for epoch in range(2):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Validation example\n",
    "with torch.no_grad():\n",
    "    x_val = torch.randn(5, 3).to(device)\n",
    "    val_output = model(x_val)\n",
    "    print(\"Validation output:\\n\", val_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71229298",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Mixed Precision & Gradient Clipping\n",
    "\n",
    "Advanced techniques for **efficient and stable training**.\n",
    "\n",
    "### Key Points\n",
    "- **Mixed precision training** (`torch.cuda.amp`)  \n",
    "  - Speeds up training on GPUs  \n",
    "  - Reduces memory usage  \n",
    "- **Gradient clipping**  \n",
    "  - Prevents exploding gradients in deep networks  \n",
    "  - Use `torch.nn.utils.clip_grad_norm_()` or `clip_grad_value_()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822bff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7234\n",
      "Epoch 2, Loss: 1.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MatenTech\\AppData\\Local\\Temp\\ipykernel_22668\\3993095.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\Users\\MatenTech\\AppData\\Local\\anaconda3\\envs\\bd\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MatenTech\\AppData\\Local\\Temp\\ipykernel_22668\\3993095.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "c:\\Users\\MatenTech\\AppData\\Local\\anaconda3\\envs\\bd\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Sample dataset\n",
    "x = torch.randn(20, 3)\n",
    "y = torch.randint(0, 2, (20,))\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# Sample model\n",
    "model = nn.Linear(3, 2).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(2):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6c071",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Practice Exercises\n",
    "\n",
    "Try the following exercises to reinforce your understanding of **PyTorch best practices**:\n",
    "\n",
    "\n",
    "\n",
    "### **Exercise 1: Device Management**\n",
    "- Check if GPU is available and set the device.  \n",
    "- Create a tensor and move it to the selected device.\n",
    "\n",
    "\n",
    "\n",
    "### **Exercise 2: Reproducibility**\n",
    "- Set seeds for `torch`, `numpy`, and Python `random`  \n",
    "- Ensure deterministic GPU results\n",
    "\n",
    "\n",
    "\n",
    "### **Exercise 3: Data Handling**\n",
    "- Create a custom `Dataset` with 10 samples of 3 features each  \n",
    "- Use `DataLoader` to batch the data (batch size = 2) and shuffle it\n",
    "\n",
    "\n",
    "\n",
    "### **Exercise 4: Model Saving & Loading**\n",
    "- Create a simple linear model  \n",
    "- Save its `state_dict` and load it back into a new model  \n",
    "- Set the loaded model to evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "### **Exercise 5: Mixed Precision & Gradient Clipping**\n",
    "- Train a simple linear model with:\n",
    "  - Mixed precision (`torch.cuda.amp`)  \n",
    "  - Gradient clipping (`clip_grad_norm_`)\n",
    "- Use a small dataset with 12 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886ca69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device: cpu\n",
      "Batch x: tensor([[ 1.6487, -0.3925, -1.4036],\n",
      "        [ 1.9269,  1.4873,  0.9007]])\n",
      "Batch y: tensor([1, 1])\n",
      "Loaded model: Linear(in_features=3, out_features=2, bias=True)\n",
      "Epoch 1, Loss: 0.6941\n",
      "Epoch 2, Loss: 0.4391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MatenTech\\AppData\\Local\\Temp\\ipykernel_22668\\2635137999.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\MatenTech\\AppData\\Local\\Temp\\ipykernel_22668\\2635137999.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 1: Device Management\n",
    "# ----------------------------\n",
    "x = torch.randn(2, 3).to(device)\n",
    "print(\"Tensor device:\", x.device)\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 2: Reproducibility\n",
    "# ----------------------------\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 3: Data Handling\n",
    "# ----------------------------\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.randn(10, 3)\n",
    "        self.labels = torch.randint(0, 2, (10,))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "for xb, yb in dataloader:\n",
    "    print(\"Batch x:\", xb)\n",
    "    print(\"Batch y:\", yb)\n",
    "    break\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 4: Model Saving & Loading\n",
    "# ----------------------------\n",
    "model = nn.Linear(3, 2)\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "\n",
    "model_loaded = nn.Linear(3, 2)\n",
    "model_loaded.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "model_loaded.eval()\n",
    "print(\"Loaded model:\", model_loaded)\n",
    "\n",
    "# ----------------------------\n",
    "# Exercise 5: Mixed Precision & Gradient Clipping\n",
    "# ----------------------------\n",
    "x_train = torch.randn(12, 3)\n",
    "y_train = torch.randint(0, 2, (12,))\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "model = nn.Linear(3, 2).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(2):\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(xb)\n",
    "            loss = loss_fn(out, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea824e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
