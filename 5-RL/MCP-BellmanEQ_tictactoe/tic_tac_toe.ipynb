{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ef6f9b",
   "metadata": {},
   "source": [
    "#  Reinforcement Learning Lab: Tic Tac Toe\n",
    "\n",
    "In this lab, you will implement a Tic Tac Toe game environment and train an RL agent to play.  \n",
    "We’ll build it step by step so that you understand **state representation, rewards, policies, and value propagation**.  \n",
    "\n",
    "\n",
    "##  Table of Contents\n",
    "- [1 - Packages](#1)  \n",
    "- [2 - Tic Tac Toe Environment](#2)  \n",
    "- [3 - Exploring Game States](#3)  \n",
    "- [4 - Players and Judger](#4)  \n",
    "- [5 - Training the AI](#5)  \n",
    "- [6 - Competing Agents](#6)  \n",
    "- [7 - Playing Against the AI](#7)  \n",
    "- [8 - Exercises](#8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de6e50",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages\n",
    "We begin by importing the basic libraries we’ll need.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae269c77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 2. Tic Tac Toe Environment\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708cab1",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Tic Tac Toe Environment\n",
    "\n",
    "The Tic Tac Toe board is a **3x3 grid**.  \n",
    "Each position can be:\n",
    "- `1` → Player 1’s move (`O`)  \n",
    "- `-1` → Player 2’s move (`X`)  \n",
    "- `0` → Empty  \n",
    "\n",
    "<img src=\"images/tictactoe_board.png\" alt=\"Tic Tac Toe Board\" width=\"250\"/>  \n",
    "\n",
    "**Your task**:  \n",
    "- Represent the board as a 3×3 numpy array.  \n",
    "- Implement methods to compute a unique hash for each state.  \n",
    "- Implement a method to check if the game has ended (win or draw).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85588def",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Tic Tac Toe Environment\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3\n",
    "\n",
    "class State:\n",
    "    def __init__(self):\n",
    "        # TODO: initialize board (3x3 zeros)\n",
    "        pass\n",
    "    \n",
    "    def hash(self):\n",
    "        # TODO: return unique hash (string or int)\n",
    "        pass\n",
    "    \n",
    "    def is_end(self):\n",
    "        # TODO: check win/draw\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1618841",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Exploring Game States\n",
    "\n",
    "There are **3⁹ possible board configurations**.  \n",
    "Not all are valid (e.g., one player might have too many moves).  \n",
    "\n",
    "**Your task**:  \n",
    "- Write a function to generate all valid states.  \n",
    "- Store them in a dictionary for later use.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddd905",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f1a52",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Exploring Game States\n",
    "# TODO: Write a recursive/iterative function to generate all valid states\n",
    "def get_all_states():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6adb8f5",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Players and Judger\n",
    "\n",
    "We need:  \n",
    "- A **Player class** → chooses an action given the state.  \n",
    "- A **Judger class** → runs the game until it ends, checks who won.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0934f56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00669e2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Player and Judger\n",
    "class Player:\n",
    "    def __init__(self, name):\n",
    "        # TODO: track name, policy, etc.\n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        # TODO: return action index (0–8)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a8ed8b",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Training the AI\n",
    "\n",
    "We now use **value iteration** or **policy evaluation** to train the agent.  \n",
    "The agent updates its value function after each game.  \n",
    "\n",
    "<img src=\"images/bellman_equation.png\" alt=\"Bellman Equation\" width=\"400\"/>  \n",
    "\n",
    "**Update rule:**  \n",
    "$$\n",
    "\\\n",
    "V(s) \\leftarrow V(s) + \\alpha \\big( R + \\gamma V(s') - V(s) \\big)\n",
    "\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d166e1c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb75964",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Training the AI\n",
    "# TODO: implement update rule\n",
    "# V(s) <- V(s) + alpha * (R + gamma * V(s') - V(s))\n",
    "def update_values():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78da44b",
   "metadata": {},
   "source": [
    "a name='6'></a>\n",
    "## 6 - Competing Agents\n",
    "\n",
    "Once trained, we let two agents compete.  \n",
    "- Agent vs Random Player  \n",
    "- Agent vs Agent  \n",
    "\n",
    "**Your task**:  \n",
    "- Run 100 games and record statistics (win/draw/loss). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa521742",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Competing Agents\n",
    "# TODO: run agent vs random agent\n",
    "def compete(agent1, agent2, n_games=100):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503505a7",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Playing Against the AI\n",
    "\n",
    "Finally, let a **human play against the AI**.  \n",
    "The board should map moves to keys:  \n",
    "\n",
    "| 0 | 1 | 2 |  \n",
    "|---|---|---|  \n",
    "| 3 | 4 | 5 |  \n",
    "| 6 | 7 | 8 |  \n",
    "\n",
    "**Your task**:  \n",
    "- Implement a loop for human vs AI.  \n",
    "- Input = position (0–8), update board, check win/draw.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306afc7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 7. Human vs AI\n",
    "def play_human_vs_ai(agent):\n",
    "    # TODO: loop for human input (0-8)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e55f3a",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## 8 - Exercises\n",
    "\n",
    "1. Change the reward scheme (e.g., +5 for win, -5 for loss).  \n",
    "   - How does it affect the agent’s strategy?  \n",
    "2. Try different learning rates `alpha`.  \n",
    "3. Play **Agent vs Agent** with different policies.  \n",
    "4. Add a graphical display for the board.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539395b1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
